{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bc853ee",
   "metadata": {
    "id": "9bc853ee"
   },
   "source": [
    "# Aufgabe: Ensemble Methoden "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4296fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importieren der Bibliotheken und Funktionen\n",
    "# Zum Beispiel den Datensatz\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Die verschiedenen Modelle aus der Aufgabe\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565d941b",
   "metadata": {},
   "source": [
    "### Aufgabe 1:\n",
    "\n",
    "Laden Sie den Wine Datensatz und trainieren Sie folgende Modelle:\n",
    "\n",
    "- [kNN Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "- [Logistische Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "- [Decision Tree Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
    "- [Random Forest Classifer](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "- [AdaBoost Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
    "\n",
    "Zeigen Sie mittels einer geeigneten Metrik, welches Modell am besten geeignet ist.\n",
    "\n",
    "Führen Sie im Anschluss all diese Modelle in ein großes Ensemble Modell zusammen. Verwenden Sie dafür den VotingClassifier von sklearn.\n",
    "\n",
    "Ist Ihr VotingClassifier leistungsstärker als die einzelnen Modelle?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906a97e7",
   "metadata": {
    "id": "906a97e7"
   },
   "outputs": [],
   "source": [
    "# Laden des Datensatzes\n",
    "data = load_wine()\n",
    "x = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e8f818",
   "metadata": {
    "id": "20e8f818",
    "outputId": "8531b220-fc8d-4b26-f459-05a8e375b892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Adaboost scored with an accuracy of 93.33%\n",
      "Model Random Forest scored with an accuracy of 97.78%\n",
      "Model Decision Tree scored with an accuracy of 88.89%\n",
      "Model Logistische Regression scored with an accuracy of 88.89%\n",
      "Model kNN scored with an accuracy of 57.78%\n",
      "Ensemble model scored with an accuracy of 95.56%\n"
     ]
    }
   ],
   "source": [
    "# Gehe durch die definierten Modelle und trainiere sie\n",
    "\n",
    "# Definiere einen Voting Classifier mit allen Modellen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7809a2b",
   "metadata": {},
   "source": [
    "\n",
    "### Aufgabe 2: Random Forest\n",
    "\n",
    "Trainieren Sie Decision Tree sowie Random Forest (zB aus sklearn) an dem von Ihnen für die Abschlussarbeit gewählten Datensatz. Visualisieren Sie (wenn möglich) das Ergebnis, welches Modell liefert bessere Ergebnisse? Welches Modell wäre vielleicht noch besser geeignet?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78dbf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Vergleich: Decision Tree vs. Random Forest ---\n",
      "Genauigkeit des Decision Tree: 88.8889\n",
      "Genauigkeit des Random Forest: 97.7778\n",
      "Detaillierter Classification Report für den Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        20\n",
      "           1       0.78      0.93      0.85        15\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.89        45\n",
      "   macro avg       0.90      0.91      0.90        45\n",
      "weighted avg       0.91      0.89      0.89        45\n",
      "\n",
      "\n",
      "Detaillierter Classification Report für den Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      0.93      0.97        15\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hier sollte ein selbst gewählter Datensatz individuell gewählt werden\n",
    "\n",
    "# Vergleiche die möglichen Metriken und Darstellung zB mit der plot_tree Funktion von sklearn"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
